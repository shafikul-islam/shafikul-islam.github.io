---
layout: default
title: Home
toc: true
---

<section class="hero-container">
  <div class="hero-content">
    <h1 class="hero-title">MD Shafikul Islam</h1>

    <div class="hero-media">
      <img class="avatar-float" src="{{ '/assets/images/profile.png' | relative_url }}" alt="Profile photo"/>
    </div>

    <p class="hero-lead">
      I am a PhD student in Mechanical and Industrial Engineering at <a href="https://www.lsu.edu/" target="_blank" rel="noopener">Louisiana State University</a> and currently serve as a <strong>Graduate Research Assistant</strong> in the <a href="https://www.lsu.edu/eng/mie/people/faculty/bappy.php" target="_blank" rel="noopener">AnalyticsIQ Lab</a>. My research targets
      <strong>cyber-physical intelligence for additive manufacturing</strong>â€”moving from <em>post-build inspection</em>
      to <strong>predictive, safety-aware, and adaptive process autonomy</strong>.
    </p>

    <p class="hero-body">
      Todayâ€™s additive manufacturing systems can print complex geometries, but they still struggle to
      <strong>perceive, diagnose, and correct</strong> defects as they form. My goal is to transform AM into a
      <strong>self-healing cyber-physical process</strong> where machines (i) sense their own behaviour through
      multi-modal signals, (ii) interpret anomalies using physics-informed AI, and (iii) adjust parameters or
      toolpaths to reduce defect formation before solidification.
    </p>

    <p class="hero-body">
      I work at the intersection of <strong>physics-based modelling</strong>, <strong>uncertainty-aware machine learning</strong>,
      and <strong>real-time robotic control</strong>. I envision distributed manufacturing systems that can
      <strong>collaborate securely</strong>â€”learning from each other without sharing sensitive dataâ€”while operators
      are guided by trustworthy AI co-pilots. The long-term direction is scalable and certifiable autonomy: turning
      trial-and-error processing into resilient, data-driven production.
    </p>

    <div class="link-badges" aria-label="Links and profiles">
      <a href="mailto:misla79@lsu.edu" class="icon-link">
        <img src="https://img.shields.io/badge/Email-EA4335?style=for-the-badge&logo=gmail&logoColor=white" alt="Email">
      </a>
      <a href="https://scholar.google.com/citations?user=A8KOQBEAAAAJ&hl=en" target="_blank" rel="noopener" class="icon-link">
        <img src="https://img.shields.io/badge/Google%20Scholar-4285F4?style=for-the-badge&logo=google-scholar&logoColor=white" alt="Google Scholar">
      </a>
      <a href="https://github.com/shafikul-islam" target="_blank" rel="noopener" class="icon-link">
        <img src="https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white" alt="GitHub">
      </a>
      <a href="https://www.linkedin.com/in/md-shafikul-islam-sohan/" target="_blank" rel="noopener" class="icon-link icon-pill icon-pill-linkedin" aria-label="LinkedIn">
        <span class="pill-icon pill-icon-linkedin" aria-hidden="true"></span>
        <span class="pill-text">LinkedIn</span>
      </a>
      <a href="https://orcid.org/0009-0007-3824-4384" target="_blank" rel="noopener" class="icon-link">
        <img src="https://img.shields.io/badge/ORCID-A6CE39?style=for-the-badge&logo=orcid&logoColor=white" alt="ORCID">
      </a>
      <a href="https://dblp.org/pid/359/9192.html" target="_blank" rel="noopener" class="icon-link">
        <img src="https://img.shields.io/badge/DBLP-004F9F?style=for-the-badge&logo=dblp&logoColor=white" alt="DBLP">
      </a>
      <a href="https://openreview.net/profile?id=~MD_Shafikul_Islam1" target="_blank" rel="noopener" class="icon-link icon-pill icon-pill-openreview" aria-label="OpenReview">
        <span class="pill-icon pill-icon-openreview" aria-hidden="true"></span>
        <span class="pill-text">OpenReview</span>
      </a>
    </div>
  </div>
</section>

<!-- ========================= -->
<!-- Research Interests -->
<!-- ========================= -->
<section class="section-interests">
  <div class="section-head">
    <h3 class="section-title">ğŸ§­ Research Interests</h3>
    <p class="section-subtitle">Core areas that guide my work in cyber-physical manufacturing and AI.</p>
  </div>

  <div class="interest-grid">
    <div class="interest-card interest-am">
      <img class="interest-icon" src="{{ '/assets/icons/Icon/additive manufacturing.png' | uri_escape | relative_url }}" alt="Additive manufacturing icon">
      <span>Additive Manufacturing</span>
    </div>
    <div class="interest-card interest-dt">
      <img class="interest-icon" src="{{ '/assets/icons/Icon/digital-twin.png' | relative_url }}" alt="Digital twin icon">
      <span>Digital Twins</span>
    </div>
    <div class="interest-card interest-edge">
      <img class="interest-icon" src="{{ '/assets/icons/Icon/edge-computing.png' | relative_url }}" alt="Edge computing icon">
      <span>Edge AI</span>
    </div>
    <div class="interest-card interest-robot">
      <img class="interest-icon" src="{{ '/assets/icons/Icon/robotics_control.png' | relative_url }}" alt="Robotics control icon">
      <span>Robotics & Control</span>
    </div>
    <div class="interest-card interest-priv">
      <img class="interest-icon" src="{{ '/assets/icons/Icon/privacy.png' | relative_url }}" alt="Privacy icon">
      <span>Privacy-Preserving Learning</span>
    </div>
    <div class="interest-card interest-trust">
      <img class="interest-icon" src="{{ '/assets/icons/Icon/trustworthy.png' | relative_url }}" alt="Trustworthy AI icon">
      <span>Trustworthy AI</span>
    </div>
  </div>
</section>

<!-- ========================= -->
<!-- Selected News -->
<!-- ========================= -->
<div class="section-news">
  <div class="card news-card">
    <div class="news-header">
      <h3 class="section-title">ğŸ—ï¸ Selected News</h3>
      <div class="news-controls">
        <button class="icon-btn" type="button" data-news-scroll="top" aria-label="Scroll to top">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="18" height="18" fill="currentColor"><path d="M11.9997 10.8284L7.04996 15.7782L5.63574 14.364L11.9997 8L18.3637 14.364L16.9495 15.7782L11.9997 10.8284Z"></path></svg>
        </button>
        <button class="icon-btn" type="button" data-news-scroll="bottom" aria-label="Scroll to bottom">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="18" height="18" fill="currentColor"><path d="M11.9997 13.1716L16.9495 8.22186L18.3637 9.63607L11.9997 16L5.63574 9.63607L7.04996 8.22186L11.9997 13.1716Z"></path></svg>
        </button>
      </div>
    </div>

    <div class="news-scroller" id="newsScroller">
      <ul class="news-items">

        <li><div class="news-date">Dec 16, 2025</div><div class="news-text">ğŸ—£ï¸ All three IISE submissions (healthcare, data analytics, and AI) were accepted for <strong>oral presentation</strong> at <strong>IISE Annual Conference & Expo 2026</strong>.</div></li>

        <li><div class="news-date">Nov 29, 2025</div><div class="news-text">âœ… Paper <em>â€œFracture Finder: Computer-Aided Real-Time Diagnosis of Vertebral Fractures in Thoracic Spine X-Rays Using YOLOv8 with Weighted Box Fusion and Augmentation Strategiesâ€</em> accepted in <em>IISE Transactions on Healthcare Systems Engineering</em>.</div></li>

        <li><div class="news-date">Nov 2025</div><div class="news-text">ğŸ“„ Paper <em>â€œInterpretable Forecasting of Dissolved Oxygen Leveraging Foundation Model for Proactive Aeration in Rural Wastewater Treatment Systemsâ€</em> published in <em>Water Research</em> (2025).</div></li>

        <li><div class="news-date">Oct 25, 2025</div><div class="news-text">ğŸ¥ˆ Runner-up, <strong>Stakeholder Engagement Data Challenge</strong> at <strong>INFORMS Annual Meeting 2025</strong>, for large-scale stakeholder analytics supporting strategy design for professional societies.</div></li>

        <li><div class="news-date">Oct 25, 2025</div><div class="news-text">ğŸ¤ Presented <em>â€œPrivacy-Aware Porosity Prediction in Metal Additive Manufacturing using Hierarchical Graph Attention Networksâ€</em> at <strong>INFORMS Annual Meeting 2025</strong>.</div></li>

        <li><div class="news-date">Oct 2025</div><div class="news-text">ğŸ… Finalist, <strong>Stakeholder Engagement Data Challenge</strong>, INFORMS Annual Meeting 2025 (team lead).</div></li>

        <li><div class="news-date">Sep 2025</div><div class="news-text">ğŸš€ Proposal recommended: <em>â€œCross-Modality Domain Adaptation for Anomaly Detection in LPBF Systemsâ€</em> (NASA EPSCoR CAN, Aug 2025).</div></li>

        <li><div class="news-date">Aug 01, 2025</div><div class="news-text">ğŸ“¢ Sports Secretary, <strong>Bangladeshi Student Association (BSA), LSU</strong>. Leading sports committees to foster community engagement among international students.</div></li>

        <li><div class="news-date">Aug 01, 2025</div><div class="news-text">ğŸ“š Three papers published in <em>Manufacturing Letters</em> (Q1).</div></li>

        <li><div class="news-date">Jul 01, 2025</div><div class="news-text">ğŸ’¡ Grant awarded: <strong>NSF LAMDA Seed Grant</strong> â€” <em>â€œPhysics-Informed ML for Process Defect Detection and Fatigue Modeling in WAAMâ€</em>.</div></li>

        <li><div class="news-date">Jun 25, 2025</div><div class="news-text">ğŸ¤ Presented three works at <strong>NAMRC 2025</strong>.</div></li>

        <li><div class="news-date">Jun 5, 2025</div><div class="news-text">âœˆï¸ <strong>NSF Student Travel Award</strong>, <strong>NAMRC 2025</strong>, supporting conference attendance.</div></li>

        <li><div class="news-date">Jun 03, 2025</div><div class="news-text">ğŸ† <strong>Champion</strong>, <strong>IISE Innovative Design Competition</strong>, IISE Annual Conference & Expo 2025, for â€œHearth AI â€” Meaningful Connection at your Fingertipsâ€.</div></li>

        <li><div class="news-date">Jun 02, 2025</div><div class="news-text">ğŸ¥‰ 2nd Runner-up, <strong>QCRE Data Challenge</strong>, IISE Annual Conference & Expo 2025.</div></li>

        <li><div class="news-date">May 31, 2025</div><div class="news-text">ğŸ¤ Presented two works at <strong>IISE 2025</strong> on <strong>graph neural networks</strong> and <strong>vision transformers</strong>.</div></li>

        <li><div class="news-date">Apr 2025</div><div class="news-text">âœˆï¸ <strong>NSF Student Travel Award</strong>, IISE Annual Conference & Expo 2025.</div></li>

        <li><div class="news-date">Febâ€“Mar 2025</div><div class="news-text">ğŸ’¼ NSF Southwest I-Corps IdeaLaunch Program: <strong>Privacy-preserving certification framework</strong> for AMaaS platforms (Role: Entrepreneurial Lead).</div></li>

        <li><div class="news-date">Mar 15, 2025</div><div class="news-text">ğŸ† Best graduate oral presentation award for <em>â€œFoundation Model-Driven Predictive and Interpretable Modeling for Critical Materials in Renewable Energy Applicationsâ€</em> (Materials Science/Engineering Division).</div></li>

        <li><div class="news-date">Jan 28, 2025</div><div class="news-text">ğŸ“„ Abstract accepted at the <strong>99th Annual Meeting</strong> of the Louisiana Academy of Sciences.</div></li>

        <li><div class="news-date">Jan 04, 2025</div><div class="news-text">ğŸ“ Started PhD in Mechanical and Industrial Engineering at LSU.</div></li>

        <li><div class="news-date">Dec 25, 2024</div><div class="news-text">ğŸ… Best Technical Presentation (Session ICCIT-2024) for â€œPredict Studentsâ€™ Performance and Optimize Preparatory Leave: An Integrated Deep Learning and Dynamic Programming Approachâ€.</div></li>

        <li><div class="news-date">Dec 26, 2024</div><div class="news-text">ğŸ‘¨ğŸ« Served as an instructor for the CIOL Winter ML Bootcamp.</div></li>

        <li><div class="news-date">Dec 16, 2024</div><div class="news-text">ğŸ—£ï¸ Two IISE abstracts accepted for oral presentation at IISE Annual Conference & Expo 2025.</div></li>

        <li><div class="news-date">Oct 01, 2024</div><div class="news-text">ğŸ‘¥ Two mentored works accepted at DigiTwin 2024 Conference.</div></li>

        <li><div class="news-date">Apr 2024</div><div class="news-text">ğŸ“ University Merit Scholarship, Shahjalal University of Science and Technology (2020â€“2024), Top 5% for four consecutive years.</div></li>

        <li><div class="news-date">Jan 2024</div><div class="news-text">ğŸ“„ Paper accepted at an AAAI-24 workshop.</div></li>

        <li><div class="news-date">Oct 2023</div><div class="news-text">ğŸ“„ Paper accepted at a NeurIPSâ€™23 workshop.</div></li>

        <li><div class="news-date">Mar 2022</div><div class="news-text">ğŸš€ Founded CIOL to bridge Industrial & Production Engineering and AI through research.</div></li>

      </ul>
    </div>
  </div>
</div>

<!-- ========================= -->
<!-- Highlights -->
<!-- ========================= -->
<div class="section-highlights">
  <h3 class="section-title">ğŸ“¸ Highlights</h3>

  <div class="hscroll">
    <div class="highlight-card">
      <div class="highlight-media">
        <img src="{{ '/assets/images/gallery/Best_paper.png' | relative_url }}" alt="Best Paper Award">
        <div class="video-chip chip-amber">Research</div>
      </div>
      <div class="highlight-body">
        <p class="highlight-title">Best Paper Award</p>
        <p class="highlight-caption">Louisiana Academy of Science, 99th Annual Meeting.</p>
      </div>
    </div>

    <div class="highlight-card">
      <div class="highlight-media">
        <img src="{{ '/assets/images/gallery/At IISE conference 2025.jpg' | relative_url }}" alt="At IISE Conference 2025">
        <div class="video-chip chip-blue">IISE 2025</div>
      </div>
      <div class="highlight-body">
        <p class="highlight-title">IISE Annual Conference</p>
        <p class="highlight-caption">Presenting research on AM reliability.</p>
      </div>
    </div>

    <div class="highlight-card">
      <div class="highlight-media">
        <img src="{{ '/assets/images/gallery/iise_innovative_design.jpg' | relative_url }}" alt="Innovative Design Competition">
        <div class="video-chip chip-green">Champion</div>
      </div>
      <div class="highlight-body">
        <p class="highlight-title">Innovative Design</p>
        <p class="highlight-caption">Champion, Hearth AI project.</p>
      </div>
    </div>

    <div class="highlight-card">
      <div class="highlight-media">
        <img src="{{ '/assets/images/gallery/Preenting My research of GNN.jpg' | relative_url }}" alt="Presenting GNN Research">
        <div class="video-chip chip-purple">Talk</div>
      </div>
      <div class="highlight-body">
        <p class="highlight-title">Technical Presentation</p>
        <p class="highlight-caption">GNNs for porosity prediction.</p>
      </div>
    </div>

    <div class="highlight-card">
      <div class="highlight-media">
        <img src="{{ '/assets/images/gallery/Presenting vision transformer paper.jpg' | relative_url }}" alt="Presenting ViT Paper">
        <div class="video-chip chip-rose">Talk</div>
      </div>
      <div class="highlight-body">
        <p class="highlight-title">Vision Transformers</p>
        <p class="highlight-caption">Real-time surface defect detection.</p>
      </div>
    </div>
  </div>
</div>

<!-- ========================= -->
<!-- Featured Research -->
<!-- ========================= -->
<div class="section-research">
  <div class="section-head">
    <h3 class="section-title">ğŸ”¬ Featured Research</h3>
    <p class="section-subtitle">A few representative projects. Full list is on the <a href="{{ '/publications/' | relative_url }}">Publications</a> page.</p>
  </div>

  <div class="research-stack">

    <!-- Paper 1 -->
    <div class="research-card research-bg-lilac">
      <div class="research-media">
        <img src="{{ '/assets/images/research/gnn_methods.png' | relative_url }}" alt="Graph neural network methodology figure">
      </div>

      <div class="research-body">
        <p class="research-title">
          Feature-Informed Differential Privacy for Graph-Augmented Porosity Detection in Laser Additive Manufacturing
        </p>

        <div class="tagrow">
          <span class="tag tag-blue">Graph ML</span>
          <span class="tag tag-purple">Privacy</span>
          <span class="tag tag-green">Additive Manufacturing</span>
        </div>

        <p class="abstract-teaser">
          Porosity control in laser-based AM is critical because pores reduce fatigue life and structural integrity.
        </p>
        <a class="text-link abstract-toggle" href="#" data-abstract-toggle aria-expanded="false">Read full abstract â†˜</a>

        <div class="abstract-full" hidden>
          <p class="abstract-paragraph">
            Yet, sharing rich in-process sensing (e.g., thermal frames) across organizations raises privacy concerns, while many learning approaches ignore the layer-wise spatial context of melt pools. We propose a feature-informed local differential privacy (FI-DP) pipeline coupled with a graph-attentional classifier for porosity detection. Each melt-pool observation is encoded by a CNN; nodes within the same build layer are connected via a k-nearest-neighbor graph constructed in a hybrid space of coordinates and learned features, and classified with a node-level GATv2. To respect privacy before graph construction, we apply local DP at the image embedding layer: Gaussian noise is allocated per-embedding coordinate according to channel importance inferred by Grad-CAM. This concentrates the privacy budget on informative directions relative to uniform noise. We also report a non-private baseline and a uniform-LDP baseline. Overall, feature-informed LDP retains much of the non-private utility while offering explicit, per-sample privacy guaranteesâ€”supporting privacy-preserving quality assurance in multi-stakeholder AM.
          </p>
          <a class="text-link subtle" href="#" data-abstract-toggle aria-expanded="true">Show less â†‘</a>
        </div>

        <div class="action-row">
          <a class="btn-mini" href="{{ '/publications/' | relative_url }}#sec-journals">ğŸ“Œ Related publications</a>
        </div>
      </div>
    </div>

    <!-- Paper 2 -->
    <div class="research-card research-bg-peach">
      <div class="research-media">
        <img src="{{ '/assets/images/research/fdm_methodology.png' | relative_url }}" alt="FDM anomaly detection methodology figure">
      </div>

      <div class="research-body">
        <p class="research-title">
          Beyond Local Receptive Fields: Vision Transformers for Real-Time Surface Defect Detection in FDM
        </p>

        <div class="tagrow">
          <span class="tag tag-rose">Vision Transformers</span>
          <span class="tag tag-amber">Real-Time</span>
          <span class="tag tag-teal">FDM</span>
        </div>

        <p class="abstract-teaser">
          Real-time quality assurance in FDM is essential, yet subtle surface anomalies are hard to capture with local receptive fields.
        </p>
        <a class="text-link abstract-toggle" href="#" data-abstract-toggle aria-expanded="false">Read full abstract â†˜</a>

        <div class="abstract-full" hidden>
          <p class="abstract-paragraph">
            Conventional defect detection methods often struggle to capture spatially distributed and subtle surface anomalies due to localized receptive fields and strong inductive biases. This study proposes an explicitly optimized method based on Vision Transformers (ViTs) for real-time surface anomaly detection in FDM. Unlike CNNs, ViTs use global self-attention, enabling long-range dependency modelling across the printed surface. The method integrates depth maps derived from 2D laser scanning to construct high-fidelity surface topology representations and supports accurate classification of key defect types. Experiments show strong performance (macro-F1 = 0.877; support-weighted mAUC = 0.972) while sustaining real-time inference.
          </p>
          <a class="text-link subtle" href="#" data-abstract-toggle aria-expanded="true">Show less â†‘</a>
        </div>

        <div class="action-row">
          <a class="btn-mini" href="{{ '/publications/' | relative_url }}#sec-conf">ğŸ“Œ Related publications</a>
        </div>
      </div>
    </div>

    <!-- Paper 3 -->
    <div class="research-card research-bg-mint">
      <div class="research-media">
        <img src="{{ '/assets/images/research/fracture_finder_method.png' | relative_url }}" alt="Fracture Finder YOLOv8 pipeline figure">
      </div>

      <div class="research-body">
        <p class="research-title">
          Fracture Finder: Real-Time Vertebral Fracture Localization on Thoracic Spine X-Rays Using YOLOv8
        </p>

        <div class="tagrow">
          <span class="tag tag-red">Medical Imaging</span>
          <span class="tag tag-orange">YOLOv8</span>
          <span class="tag tag-green">Real-Time</span>
        </div>

        <p class="abstract-teaser">
          Vertebral fractures can be missed under time pressure; fast localization support can reduce oversight and triage delays.
        </p>
        <a class="text-link abstract-toggle" href="#" data-abstract-toggle aria-expanded="false">Read full abstract â†˜</a>

        <div class="abstract-full" hidden>
          <p class="abstract-paragraph">
            We propose Fracture Finder, a single-stage deep-learning system that localizes suspected acute fractures with bounding boxes and returns confidence scores in real-time. Built on the YOLOv8 detection backbone, the model processes a typical X-ray in â‰ˆ126 ms on a mid-range consumer GPU. The model was trained and validated on 1247 expert-annotated images from the UTMB-1000 dataset. Exploratory analysis showed class imbalance and systematic patterns in bounding-box size and position. We addressed these with targeted oversampling and augmentation. On a hold-out set, Fracture Finder achieves strong detection performance and supports expedited review by flagging suspicious cases with low latency.
          </p>
          <a class="text-link subtle" href="#" data-abstract-toggle aria-expanded="true">Show less â†‘</a>
        </div>

        <div class="action-row">
          <a class="btn-mini" href="https://doi.org/10.1080/24725579.2025.2598578" target="_blank" rel="noopener">ğŸ”— DOI</a>
        </div>
      </div>
    </div>

  </div>

  <div class="center-cta">
    <a href="{{ '/publications/' | relative_url }}" class="btn">ğŸ“š See Full Research & Publications â†’</a>
  </div>
</div>
